{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing for STATIC DATASET RL IS IT WORK??????'''\n",
    "'''RL for Classification'''\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.autograd import Variable\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import gym\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "## Credit Card Data를 이용\n",
    "train = pd.read_csv(\"./uci_creditcard-train-0.0-0.0.csv\")\n",
    "test = pd.read_csv(\"./uci_creditcard-test-0.0-0.0.csv\")\n",
    "\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "\n",
    "plt.ion()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''열별로 데이터 전처리하는 과정 '''\n",
    "def z_score_normalize(data) :\n",
    "    normal_data = data\n",
    "    for columns in range(data.shape[1]-2) :\n",
    "        normal_data[:][columns] = (data[:][columns] - np.mean(data[:][columns])) /\\\n",
    "                                    np.std(data[:][columns])\n",
    "\n",
    "    return normal_data\n",
    "\n",
    "\n",
    "normalized_train = z_score_normalize(train)\n",
    "normalized_test = z_score_normalize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experience Replay\n",
    "## 학습에 이용할 메모리\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, transition):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(transition)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        if len(self.memory) >= self.capacity: \n",
    "            self.memory[self.position] = transition\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 큰 차원의 데이터를 다루기위해서 사용\n",
    "\n",
    "\n",
    "## 학습에 쓰이는  NN \n",
    "## Input은 State가 되고 Output은 Q - value가 된다.\n",
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, action_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size,hidden_size*2)\n",
    "        self.fc3 = nn.Linear(hidden_size*2,hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size,1) ## Classification에서 0을 선택할 확률이 OUTPUT \n",
    "       \n",
    "        \n",
    "    ## 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됨.\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = F.relu(self.fc3(x))\n",
    "        ## 마지막 결과값이 확률로 나오게 만듬 . \n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "\n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter\n",
    "BATCH_SIZE = 100\n",
    "hidden_size = 100\n",
    "train_num = 5000\n",
    "\n",
    "## Input data size는 Column의 개수 -1 마지막 두개의 열은 Classification과 Valide Set을 구분.\n",
    "input_size = train.shape[1]-3\n",
    "## Classification 이므로 Action은 2가 나옴.\n",
    "action_size = 2\n",
    "\n",
    "## 큰 차원의 데이터를 처리하기 위해서 NN을 사용\n",
    "policy_net = NN(input_size,hidden_size, action_size)\n",
    "target_net = NN(input_size,hidden_size, action_size)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "## 최적화 기준 RMS(Root Mean Squeare)\n",
    "optimizer = optim.RMSprop(policy_net.parameters(), lr =0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reward를 받을 때 데이터셋의 비율이 다르므로 Reward도 다르게 적용\n",
    "def get_reward(action,target) :\n",
    "    if action == target :\n",
    "        accuracy = 1\n",
    "        if action == 1 : \n",
    "            reward = 23996 / 5356\n",
    "        elif action == 0 :\n",
    "            reward = 23996 / 18640\n",
    "    else :\n",
    "        accuracy = 0\n",
    "        if action == 1 :\n",
    "            reward = -23996 / 5356\n",
    "        elif action == 0 :\n",
    "            reward = - 23996 / 18640\n",
    "    \n",
    "    return reward,accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations(reward):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    reward = torch.FloatTensor(reward)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    #plt.axhline(y=90,linestyle ='--')\n",
    "    plt.plot(reward.numpy())\n",
    "    if len(reward) >= 100:\n",
    "        means = reward.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "\n",
    "\n",
    "## Traing set을 이용한 학습 \n",
    "##\n",
    "for i_num in range(train_num):\n",
    "    ## Batch size 크기 만큼의 Trajectory가 만들어짐.\n",
    "    trajectory = normalized_train[np.random.choice(normalized_train.shape[0],BATCH_SIZE,replace =False),:]\n",
    "    total_acc = 0\n",
    "    ## Discout factor\n",
    "    GAMMA = 0.99\n",
    "    ## Trajectory를 만듬 길이는 BATCH_SIZE\n",
    "    ## Gradient Descent\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    total_loss = 0\n",
    "    ## Trajectory를 따라가면서 학습\n",
    "    for t in range(BATCH_SIZE) :      \n",
    "        ## state를 tensor로 바꿔서 이용\n",
    "        state = trajectory[t][1:24]\n",
    "        state = torch.FloatTensor(state)\n",
    "        state = Variable(state)\n",
    "        ## Classification Target\n",
    "        target = trajectory[t][24]\n",
    "        \n",
    "        ## Action을 선택하기 위해 이항분포 => Discrete Action space\n",
    "        probs = policy_net(state)\n",
    "        m = Bernoulli(probs)\n",
    "        action = m.sample()\n",
    "        action = action.data.numpy().astype(int)[0]\n",
    "        ## With Discout reward\n",
    "        reward,accuracy= get_reward(action,target)\n",
    "        if t >1 : \n",
    "            reward = reward * GAMMA\n",
    "        total_acc += accuracy\n",
    "        \n",
    "        GAMMA = GAMMA * 0.99\n",
    "        \n",
    "        loss = -m.log_prob(action) * reward  ## Negtive score function x reward\n",
    "        total_loss += loss\n",
    "        \n",
    "    total_accuracy.append(total_acc)\n",
    "    loss = total_loss / BATCH_SIZE\n",
    "    if (i_num+1) % 10 == 0 :\n",
    "        print('Current_train_num : ',i_num, \"LOSS : \",loss.item())\n",
    "    loss.backward()\n",
    "    ## Optimize\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i_num+1) % 100 == 0 :\n",
    "        plot_durations(total_accuracy)\n",
    "    if (i_num+1) % 500 ==0 :\n",
    "        clear_output()\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "target_net.load_state_dict(policy_net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_accuracy = []\n",
    "test_num = 6004 ## Test set의 행의 크기\n",
    "total_acc = 0\n",
    "\n",
    "##Test set을 이용한 확인 \n",
    "##\n",
    "for i_num in range(test_num):\n",
    "    \n",
    "    state = normalized_test[i_num][1:24]\n",
    "    \n",
    "    ## state를 tensor로 바꿔서 이용\n",
    "    state = torch.FloatTensor(state)\n",
    "    state = Variable(state)\n",
    "    ## Classification Target\n",
    "    target = normalized_test[i_num][24]\n",
    "\n",
    "    ## Action을 선택하기 위해 이항분포 => Discrete Action space\n",
    "    probs = target_net(state)\n",
    "    m = Bernoulli(probs)\n",
    "    action = m.sample()\n",
    "    action = action.data.numpy().astype(int)[0]\n",
    "    _,accuracy= get_reward(action,target)\n",
    "\n",
    "    total_acc += accuracy   \n",
    "    total_accuracy.append(total_acc)\n",
    "    if (i_num+1) % 10 == 0 :\n",
    "        print('Current_train_num : ',i_num, \"Accuracy : \",total_acc / i_num)\n",
    "\n",
    "    if (i_num+1) % 100 == 0 :\n",
    "        plot_durations(total_accuracy)\n",
    "    if (i_num+1) % 500 ==0 :\n",
    "        clear_output()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULT (Correct / Total Test NUM) :    0.7837747792770281\n",
      "Total Test Num =  6004\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL RESULT (Correct / Total Test NUM) :   \", total_acc / i_num  )\n",
    "print(\"Total Test Num = \", test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments : PG를 이용해서 Classification 문제를 해결하려고 시도해보았다. 성능은 높게 나오진 않았지만, 정형 데이터에서 강화학습 알고리즘을 이용할 수 있을 것 같다.(정형 데이터에 강화학습 알고리즘을 이용해서 Classification 문제를 해결하는 것이 강화학습이라고 할 수 있을까?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
